<style>
    .rwd-video {
      height: 0;
      overflow: hidden;
      padding-bottom: 56.25%;
      padding-top: 30px;
      position: relative;
    }
    .rwd-video iframe,
    .rwd-video object,
    .rwd-video embed {
        height: 100%;
        left: 0;
        position: absolute;
        top: 0;
        width: 100%;
    }
</style>


<section class="hero  has-text-centered" id="paper">
    <div class="hero-body">
        <div class="container">
          <h2 align="centered" class="title">PAPER</h2>
            <div class="columns">
                <div class="column is-one-fifth-desktop is-one-fifth-tablet is-one-fifth-fullhd">
                  <br>
                  <br>
                  <br>
                  <a href="">
                  <img style="width:90%" src="assets/paper.png" >
                  </a>
                </div>
                <div class="column has-text-left-desktop has-text-left-tablet has-text-left-fullhd has-text-left-widescreen">

                    <br>
                    <div class="container columns is-centered">
                        <div>
                          <B><a href="">RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation</a><br><br></B>
                          <B><i>Fabio Tosi*, Pierluigi Zama Ramirez*, Matteo Poggi*, Samuele Salti, Stefano Mattoccia, Luigi Di Stefano</B></i>
                          <br>
                          <i>*Equal Contribution</i>
                          <br>
                          <br>
                          <p>                                                   
                          We address the problem of registering synchronized color (RGB) and multi-spectral (MS) images featuring very different resolution by solving stereo matching correspondences. Purposely, we introduce a novel RGB-MS dataset framing 13 different scenes in indoor environments and providing a total of 34 image pairs annotated with semi-dense, high-resolution ground-truth labels in the form of disparity maps. To tackle the task, we propose a deep learning architecture trained in a self-supervised manner by exploiting a further RGB camera, required only during training data acquisition. In this setup, we can conveniently learn cross-modal matching in the absence of ground-truth labels by distilling knowledge from an easier RGB-RGB matching task based on a collection of about 11K unlabeled image triplets. Experiments show that the proposed pipeline sets a good performance bar (1.16 pixels average registration error) for future research on this novel, challenging task.
                        </div>
                    </div>
                </div>
            </div>
            <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                CITATION
                </h3>
                <div class="has-text-left-desktop has-text-left-tablet has-text-left-fullhd has-text-left-widescreen form-group col-md-18 col-md-offset-0">
                <pre>
                    @inproceedings{tosi2022booster,
                        title={RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation},
                        author={Tosi, Fabio and Zama Ramirez, Pierluigi and Poggi, Matteo and Salti, Samuele and Di Stefano, Luigi and Mattoccia, Stefano},
                        booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
                        note={CVPR},
                        year={2022},
                    }
                </pre>
                </div>
            </div>
            </div>  
        </div>
        </div>
</section>

<section class="hero has-text-centered has-background-white" id="dataset">
    <div class="hero-body">
        <div class="container">
            <div class="rwd-video">
            <iframe src="https://www.youtube.com/embed/dmN23_rnmjQ">
            </iframe>
            </div>
        </div> 
    </div>        
</section>
